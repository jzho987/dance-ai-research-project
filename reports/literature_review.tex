%% 
%% Copyright 2007-2020 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
\documentclass[final,5p,times,twocolumn,authoryear]{article}

\usepackage{amssymb}
\usepackage{cite}

\begin{document}

\title{Literature Review of Modern Motion and Dance Synthesis Techniques and Their Benefits and Flaws}
\author{Jiazhi Zhou}
\maketitle

\begin{abstract}

This literature review contributes to the research towards better embodiment experience in VR technology. The results of this review will allow the research team to deploy the appropriate model for the given purpose of the experiments and observe the reactions of users to the model.

\end{abstract}

\section{Introduction}

TODO: write

\section{Deep Learning}

Machine learning and deep learning has been a popular topic in recent years. Showing incredible results for text generation, image generation and much more.
Using deep learning techniques to train machine learning models could enable the generation of realistic responses to user's full body inputs in a VR or public installation setting.
This can not only prompt the users to explore different movements in order to have a better embodied experience, not also prompt user interactions with the installation, or become a potent tool for co-creative purposes \cite{Wallace2023}.
Different techniques and models will be reviewed and examined on their abilities to generate realistic, diverse and real-time dances for the purpose of an interactive AI agent.

Alemi et al. explored the idea of an interactive AI agent \cite{Alemi2017}. Alemi et al. compared the Factored Conditional Restricted Boltzman Machine (FCRBM) and a Long Short Term Memory (LSTM) network. And at the time, there was not a large public annotated dance dataset available like AIST++ \cite{Li2021}, so Alemi et al. had to record their own dance data which only consisted of 4 dance performances and a total of 23 minutes of dance and audio data.



\section*{Acknowledgements}
Thanks to ...

\bibliographystyle{plain} 
\bibliography{mybib}

\end{document}
\endinput
